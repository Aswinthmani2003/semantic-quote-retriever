# -*- coding: utf-8 -*-
"""AI Assignment - Task 2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mT9PSQHZI-ORqEiZdPGqxIhJrhcJ0pdV
"""

!pip install --upgrade datasets fsspec huggingface_hub

from IPython import get_ipython
from IPython.display import display
from datasets import load_dataset

dataset = load_dataset("Abirate/english_quotes", split="train")
# dataset = dataset.remove_columns(["index"])  # Clean up - This column does not exist
dataset = dataset.filter(lambda x: x["quote"] and x["author"])
dataset = dataset.shuffle(seed=42)
dataset = dataset.select(range(1000))  # Optional: use subset

dataset[0]

from sentence_transformers import SentenceTransformer

model = SentenceTransformer("all-MiniLM-L6-v2")
quotes_list = dataset["quote"]
quote_embeddings = model.encode(quotes_list, show_progress_bar=True)

!pip install faiss-cpu
import faiss
import numpy as np

embedding_dim = quote_embeddings.shape[1]
index = faiss.IndexFlatL2(embedding_dim)
index.add(np.array(quote_embeddings))

def retrieve_quotes(query, dataset, top_k=5):
        query_embedding = model.encode([query])
        scores, indices = index.search(np.array(query_embedding), top_k)

        results = []
        # Extract the lists of quotes, authors, and tags from the dataset
        quotes = dataset["quote"]
        authors = dataset["author"]
        # The original dataset does not contain a 'tags' column, so we'll skip it or handle its absence.
        # Based on the traceback, it seems 'tags' was expected. Let's assume it should have been there or
        # remove it if it's not. Since the original data does not have 'tags', let's remove that part.
        # If your dataset was supposed to have 'tags', ensure that column exists.

        for i in indices[0]:
            results.append({
                "quote": quotes[i],
                "author": authors[i],
                # "tags": tags[i] # Remove or adjust if 'tags' column doesn't exist in dataset
            })
        return results

# sample:
# Now call the function with the dataset
retrieve_quotes("funny quotes about women authors", dataset)

def format_as_rag_response(query, top_k=5):
    results = retrieve_quotes(query, top_k)
    response = f"ðŸ” **Query:** {query}\n\n"
    for r in results:
        response += f"> *{r['quote']}*  â€” **{r['author']}**  \n"
    return response

!pip install streamlit
import streamlit as st

st.title("Semantic Quote Search (RAG Style)")
query = st.text_input("Enter a query:", "")

if query:
    results = retrieve_quotes(query, top_k=5)
    for r in results:
        st.markdown(f"> *{r['quote']}*  \n\nâ€” **{r['author']}**")
        st.markdown("---")

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py

!streamlit run app.py

